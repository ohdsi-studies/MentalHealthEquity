# Executive Summary 

**Author:** Jacob Scott Zelko

**Date:** 2022-11-02

**Summary:** A feasibility assessment to assess candidacy of partner site location 

# Running Feasbility Assessment

## Packages 

The following packages will be loaded to conduct the feasibility assessment:

```{r, eval = FALSE, message = FALSE}
library(DatabaseConnector)
library(dplyr)
library(ggplot2)
library(lubridate)
library(readr)
library(SqlRender)
library(tibble)
```

To learn more about these packages, see the [Appendix](#appendix).

## Defining Connection Details

Here, we need to set-up connection to the OMOP CDM database we will assess.
To do so, we need to define some constants that will be used for the connection.
The following list of constants:

- `dbms` - the database management system that is used to host your database; common options include (see all options [here](http://ohdsi.github.io/DatabaseConnector/reference/createConnectionDetails.html)):
	- `"postgresql"`
	- `"sql server"`
- `server` - name of the server; could be `localhost`, an address like `123.0.1.5`, etc. 
- `user` - your username to access the server 
- `password` - the password you use to access the server 
- `port` - the port where the database is hosted
- `schema` - name of the database schema used

Must be defined in this code block (change `eval = FALSE` to `eval = FALSE` when you have set these variables correctly): 

```{r, eval = FALSE}
dbms <- "Fill in here"
server <- "Fill in here"
user <- "Fill in here"
password <- "Fill in here"
port <- "Fill in here"
schema <- "Fill in here"
```

An additional step needed is to configure the required driver to connect to the database as follows: 

1. Determine the name of your database management system based on the list [here](http://ohdsi.github.io/DatabaseConnector/reference/downloadJdbcDrivers.html)
2. Download the drivers by running the following:

This is accomplished in the following codeblock (change `eval = FALSE` to `eval = FALSE` when you have set these variables correctly):
	
```{r, eval = FALSE}
pathToDriver <- "/location/that/you/want"
downloadJdbcDrivers(dbms = dbms, pathToDriver = pathToDriver, method = "auto")
```

Once this is done, we can create the connection to the database (change `eval = FALSE` to `eval = FALSE` when you have set these variables correctly): 

```{r, eval = FALSE} 
connectionDetails <- createConnectionDetails(dbms=dbms, 
                                             server=server,
                                             user=user,
					     password=password,
					     port=port,
					     pathToDriver=pathToDriver)

connection <- connect(connectionDetails)
```

If there were no errors, then we should be able to continue with the analysis! 

> WARN: As you proceed with this analysis, if you encounter a Java issue like this: "Insufficient java heap memory", please run the following code block:
> 
> ````{r, eval = FALSE}
> options(java.parameters = c("-XX:+UseConcMarkSweepGC", "-Xmx8192m"))
> ````
> This is only an emergency work around and should be removed when a better solution is found.

### Example Connection 

If any of this was confusing, here is an example of how to fill out the above connection information:

```{r, eval = FALSE}
dbms <- "postgresql"
server <- "test.data.americus.edu/mimic_omop"
user <- "mimic"
password <- "omoprocks"
port <- 5042
schema <- "mimic.omop"

pathToDriver = "utils"
downloadJdbcDrivers(dbms = dbms, pathToDriver = pathToDriver, method = "auto")

connectionDetails <- createConnectionDetails(dbms=dbms, 
                                             server=server,
                                             user=user,
                                             password=password,
					     port=port,
					     pathToDriver=pathToDriver)

connection <- connect(connectionDetails)
```

## Queries

There are a number of queries to execute that will take varying amounts of time depending on how many patients are in your database and how much data is at your site.

### Stratified Person Query 

TODO: Add requirements to run query

**Desc:** A compact query to get all persons by race, gender, and age group (thanks to Sarah Gasman for the suggestion!). 
For the purpose of this analysis, the subtrahend value is calculated based on the latest recorded date found in the `observation_period` table (considered by OHDSI experts to be the table with the latest information in a database).

```{r, eval = TRUE}
source("./sql/stratified_person.R")
```

### Care Site Query

TODO: Add requirements to run query

**Desc:** Gets counts of distinct care site types present in database:

```{r, eval = TRUE}
source("./sql/care_sites.R")
```

### State Person Query

TODO: Add requirements to run query

**Desc:** Gets counts of persons broken down by state:

```{r, eval = FALSE}
source("./sql/state_person.R")
```

### Visit Type Query 

TODO: Add requirements to run query

**Desc:** Count of unique visits across types of visits

```{r, eval = FALSE}
source("./sql/visit_type.R")
```

## Analyses to Conduct

TODO: Put each corresponding analysis with its respective query file 

### Breakdown by Race, Gender, and Age Group

Here, we look at breakdowns by race, gender, and age group of persons.

#### Aggregation and Privacy Preserving

Now we enforce aggregation and [HITECH standards](https://www.hhs.gov/hipaa/for-professionals/special-topics/hitech-act-enforcement-interim-final-rule/index.html) for filtering:

```{r, eval = FALSE}
person_stratified_counts <- person_stratified %>% 
filter(counts> 10)
```

#### Export 

Now, all we need to do is export the data: 

```{r, eval = FALSE}
write.table(person_stratified_counts, file = "data/exp_raw/person_stratified_breakdown.csv")
```

### Breakdown by Care Site 

For this, all we need to do is export the data: 

```{r, eval = FALSE}
write.table(care_sites, file = "data/exp_raw/care_site_breakdown.csv")
```

### Breakdown by Visit Type 

For this, all we need to do is export the data: 

```{r, eval = FALSE}
write.table(visit_types, file = "data/exp_raw/visit_type_breakdown.csv")
```

### Breakdown by State

#### Enforce Privacy 

Here we must enforce [HITECH standards](https://www.hhs.gov/hipaa/for-professionals/special-topics/hitech-act-enforcement-interim-final-rule/index.html) for filtering:

```{r, eval = FALSE}
location <- location %>% 
filter(COUNT > 10)
```

#### Export 

Now, all we need to do is export the data: 

```{r, eval = FALSE}
write.table(location, file = "data/exp_raw/location_breakdown.csv")
```

# Conclusion

## Next Steps

With this feasibility analysis done, please share the results back to us at GTRI. 
Feel free to contact us at `jacob.zelko@gtri.gatech.edu` and we can discuss further steps.

## THANK YOU! 

If you completed this entire feasibility assessment, **THANK YOU**! 
You are making this network study possible and my team and I at GTRI fully understand how difficult getting these assessments to run can be!
We look forward to collaborating further!

# Appendix 

## Packages Details

- [`renv`](https://rstudio.github.io/renv/index.html) - create reproducible environments for R projects
- [`ggplot2`](https://ggplot2.tidyverse.org) - system for declaratively creating graphics
- [`dplyr`](https://dplyr.tidyverse.org) - grammar for data manipulation
- [`tibble`](https://tibble.tidyverse.org) - improved data.frame functionality
- [`SqlRender`](https://ohdsi.github.io/SqlRender/) - package for rendering parameterized SQL
- [`DatabaseConnector`](http://ohdsi.github.io/DatabaseConnector/) - package for connecting to databases using JDBC

TODO: Update packages used list
